{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8fa01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flaml\n",
      "  Downloading FLAML-2.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: NumPy>=1.17 in /root/venv/lib/python3.7/site-packages (from flaml) (1.18.5)\n",
      "Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: flaml\n",
      "Successfully installed flaml-2.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed963103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /root/venv/lib/python3.7/site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: scipy in /root/venv/lib/python3.7/site-packages (from lightgbm) (1.7.3)\n",
      "Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b97e3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/venv/lib/python3.7/site-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "Successfully installed pip-24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f43709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polars\n",
      "  Downloading polars-0.18.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.1 in /root/venv/lib/python3.7/site-packages (from polars) (4.7.1)\n",
      "Downloading polars-0.18.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: polars\n",
      "Successfully installed polars-0.18.4\n"
     ]
    }
   ],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebdb07",
   "metadata": {},
   "source": [
    "## Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e95105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time,os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from flaml import AutoML\n",
    "import polars as pl\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2866c",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f5f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test datasets\n",
    "train = pl.read_csv('train.csv')\n",
    "test = pl.read_csv('test.csv')\n",
    "submission=pl.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf61cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "shape: (5, 3)\n",
      "┌──────────┬───────────────────────────────────┬───────┐\n",
      "│ essay_id ┆ full_text                         ┆ score │\n",
      "│ ---      ┆ ---                               ┆ ---   │\n",
      "│ str      ┆ str                               ┆ i64   │\n",
      "╞══════════╪═══════════════════════════════════╪═══════╡\n",
      "│ 000d118  ┆ Many people have car where they … ┆ 3     │\n",
      "│ 000fe60  ┆ I am a scientist at NASA that is… ┆ 3     │\n",
      "│ 001ab80  ┆ People always wish they had the … ┆ 4     │\n",
      "│ 001bdc0  ┆ We all heard about Venus, the pl… ┆ 4     │\n",
      "│ 002ba53  ┆ Dear, State Senator               ┆ 3     │\n",
      "│          ┆                                   ┆       │\n",
      "│          ┆ This is a l…                      ┆       │\n",
      "└──────────┴───────────────────────────────────┴───────┘\n",
      "\n",
      "test :\n",
      "shape: (3, 2)\n",
      "┌──────────┬───────────────────────────────────┐\n",
      "│ essay_id ┆ full_text                         │\n",
      "│ ---      ┆ ---                               │\n",
      "│ str      ┆ str                               │\n",
      "╞══════════╪═══════════════════════════════════╡\n",
      "│ 000d118  ┆ Many people have car where they … │\n",
      "│ 000fe60  ┆ I am a scientist at NASA that is… │\n",
      "│ 001ab80  ┆ People always wish they had the … │\n",
      "└──────────┴───────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of each dataset\n",
    "print(\"train:\")\n",
    "print(train.head())\n",
    "print(\"\\ntest :\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ed445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17307\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d042206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for train dataset:\n",
      "shape: (9, 4)\n",
      "┌────────────┬──────────┬───────────────────────────────────┬──────────┐\n",
      "│ describe   ┆ essay_id ┆ full_text                         ┆ score    │\n",
      "│ ---        ┆ ---      ┆ ---                               ┆ ---      │\n",
      "│ str        ┆ str      ┆ str                               ┆ f64      │\n",
      "╞════════════╪══════════╪═══════════════════════════════════╪══════════╡\n",
      "│ count      ┆ 17307    ┆ 17307                             ┆ 17307.0  │\n",
      "│ null_count ┆ 0        ┆ 0                                 ┆ 0.0      │\n",
      "│ mean       ┆ null     ┆ null                              ┆ 2.948402 │\n",
      "│ std        ┆ null     ┆ null                              ┆ 1.044899 │\n",
      "│ min        ┆ 000d118  ┆ \"                                 ┆ 1.0      │\n",
      "│            ┆          ┆                                   ┆          │\n",
      "│            ┆          ┆ All of our development since …    ┆          │\n",
      "│ max        ┆ fffed3e  ┆ ¨Wow look at that car it´s the k… ┆ 6.0      │\n",
      "│ median     ┆ null     ┆ null                              ┆ 3.0      │\n",
      "│ 25%        ┆ null     ┆ null                              ┆ 2.0      │\n",
      "│ 75%        ┆ null     ┆ null                              ┆ 4.0      │\n",
      "└────────────┴──────────┴───────────────────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for train dataset:\")\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3033ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for test dataset :\n",
      "shape: (9, 3)\n",
      "┌────────────┬──────────┬───────────────────────────────────┐\n",
      "│ describe   ┆ essay_id ┆ full_text                         │\n",
      "│ ---        ┆ ---      ┆ ---                               │\n",
      "│ str        ┆ str      ┆ str                               │\n",
      "╞════════════╪══════════╪═══════════════════════════════════╡\n",
      "│ count      ┆ 3        ┆ 3                                 │\n",
      "│ null_count ┆ 0        ┆ 0                                 │\n",
      "│ mean       ┆ null     ┆ null                              │\n",
      "│ std        ┆ null     ┆ null                              │\n",
      "│ min        ┆ 000d118  ┆ I am a scientist at NASA that is… │\n",
      "│ max        ┆ 001ab80  ┆ People always wish they had the … │\n",
      "│ median     ┆ null     ┆ null                              │\n",
      "│ 25%        ┆ null     ┆ null                              │\n",
      "│ 75%        ┆ null     ┆ null                              │\n",
      "└────────────┴──────────┴───────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics for test dataset :\")\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692e2c5",
   "metadata": {},
   "source": [
    "## Applying Vectorization and LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30059d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 04-09 20:00:05] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 04-09 20:00:05] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 04-09 20:00:06] {1789} INFO - Minimizing error metric: 1-macro_f1\n",
      "[flaml.automl.logger: 04-09 20:00:06] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl.logger: 04-09 20:00:06] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:06] {2346} INFO - Estimated sufficient time budget=8111s. Estimated necessary time budget=8s.\n",
      "[flaml.automl.logger: 04-09 20:00:06] {2398} INFO -  at 0.9s,\testimator lgbm's best error=0.9072,\tbest estimator lgbm's best error=0.9072\n",
      "[flaml.automl.logger: 04-09 20:00:06] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:07] {2398} INFO -  at 1.9s,\testimator lgbm's best error=0.9072,\tbest estimator lgbm's best error=0.9072\n",
      "[flaml.automl.logger: 04-09 20:00:07] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:08] {2398} INFO -  at 2.3s,\testimator lgbm's best error=0.7609,\tbest estimator lgbm's best error=0.7609\n",
      "[flaml.automl.logger: 04-09 20:00:08] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:09] {2398} INFO -  at 4.0s,\testimator lgbm's best error=0.5709,\tbest estimator lgbm's best error=0.5709\n",
      "[flaml.automl.logger: 04-09 20:00:09] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:10] {2398} INFO -  at 4.5s,\testimator lgbm's best error=0.5709,\tbest estimator lgbm's best error=0.5709\n",
      "[flaml.automl.logger: 04-09 20:00:10] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:12] {2398} INFO -  at 6.6s,\testimator lgbm's best error=0.5709,\tbest estimator lgbm's best error=0.5709\n",
      "[flaml.automl.logger: 04-09 20:00:12] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:16] {2398} INFO -  at 10.2s,\testimator lgbm's best error=0.5709,\tbest estimator lgbm's best error=0.5709\n",
      "[flaml.automl.logger: 04-09 20:00:16] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:16] {2398} INFO -  at 11.1s,\testimator lgbm's best error=0.5709,\tbest estimator lgbm's best error=0.5709\n",
      "[flaml.automl.logger: 04-09 20:00:16] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:24] {2398} INFO -  at 18.3s,\testimator lgbm's best error=0.5474,\tbest estimator lgbm's best error=0.5474\n",
      "[flaml.automl.logger: 04-09 20:00:24] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:00:26] {2398} INFO -  at 20.8s,\testimator lgbm's best error=0.5474,\tbest estimator lgbm's best error=0.5474\n",
      "[flaml.automl.logger: 04-09 20:00:26] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:05] {2398} INFO -  at 59.4s,\testimator lgbm's best error=0.5474,\tbest estimator lgbm's best error=0.5474\n",
      "[flaml.automl.logger: 04-09 20:01:05] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:12] {2398} INFO -  at 66.3s,\testimator lgbm's best error=0.5474,\tbest estimator lgbm's best error=0.5474\n",
      "[flaml.automl.logger: 04-09 20:01:12] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:16] {2398} INFO -  at 70.1s,\testimator lgbm's best error=0.5474,\tbest estimator lgbm's best error=0.5474\n",
      "[flaml.automl.logger: 04-09 20:01:16] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:24] {2398} INFO -  at 78.7s,\testimator lgbm's best error=0.5450,\tbest estimator lgbm's best error=0.5450\n",
      "[flaml.automl.logger: 04-09 20:01:24] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:33] {2398} INFO -  at 87.5s,\testimator lgbm's best error=0.5317,\tbest estimator lgbm's best error=0.5317\n",
      "[flaml.automl.logger: 04-09 20:01:33] {2219} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:55] {2398} INFO -  at 109.7s,\testimator lgbm's best error=0.5317,\tbest estimator lgbm's best error=0.5317\n",
      "[flaml.automl.logger: 04-09 20:01:55] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:01:59] {2398} INFO -  at 113.3s,\testimator lgbm's best error=0.5317,\tbest estimator lgbm's best error=0.5317\n",
      "[flaml.automl.logger: 04-09 20:01:59] {2219} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:02:23] {2398} INFO -  at 137.4s,\testimator lgbm's best error=0.5317,\tbest estimator lgbm's best error=0.5317\n",
      "[flaml.automl.logger: 04-09 20:02:23] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:02:25] {2398} INFO -  at 139.1s,\testimator lgbm's best error=0.5317,\tbest estimator lgbm's best error=0.5317\n",
      "[flaml.automl.logger: 04-09 20:02:25] {2219} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:02:28] {2398} INFO -  at 142.7s,\testimator lgbm's best error=0.5317,\tbest estimator lgbm's best error=0.5317\n",
      "[flaml.automl.logger: 04-09 20:02:28] {2219} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:02:45] {2398} INFO -  at 159.3s,\testimator lgbm's best error=0.5296,\tbest estimator lgbm's best error=0.5296\n",
      "[flaml.automl.logger: 04-09 20:02:45] {2219} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:03:16] {2398} INFO -  at 190.5s,\testimator lgbm's best error=0.5274,\tbest estimator lgbm's best error=0.5274\n",
      "[flaml.automl.logger: 04-09 20:03:16] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:03:32] {2398} INFO -  at 206.9s,\testimator lgbm's best error=0.5274,\tbest estimator lgbm's best error=0.5274\n",
      "[flaml.automl.logger: 04-09 20:03:32] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:04:01] {2398} INFO -  at 235.2s,\testimator lgbm's best error=0.4991,\tbest estimator lgbm's best error=0.4991\n",
      "[flaml.automl.logger: 04-09 20:04:01] {2219} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:05:38] {2398} INFO -  at 332.7s,\testimator lgbm's best error=0.4991,\tbest estimator lgbm's best error=0.4991\n",
      "[flaml.automl.logger: 04-09 20:05:38] {2219} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:06:00] {2398} INFO -  at 354.9s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:06:00] {2219} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:06:35] {2398} INFO -  at 389.5s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:06:35] {2219} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:06:59] {2398} INFO -  at 413.7s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:06:59] {2219} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:07:06] {2398} INFO -  at 420.6s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:07:06] {2219} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:08:37] {2398} INFO -  at 511.2s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:08:37] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:08:45] {2398} INFO -  at 519.3s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:08:45] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 04-09 20:09:59] {2398} INFO -  at 594.0s,\testimator lgbm's best error=0.4956,\tbest estimator lgbm's best error=0.4956\n",
      "[flaml.automl.logger: 04-09 20:10:22] {2628} INFO - retrain lgbm for 22.1s\n",
      "[flaml.automl.logger: 04-09 20:10:22] {2631} INFO - retrained model: LGBMClassifier(learning_rate=0.10523786258143789, max_bin=255,\n",
      "               min_child_samples=6, n_estimators=1, n_jobs=-1, num_leaves=4,\n",
      "               reg_alpha=0.06412115021351315, reg_lambda=0.5056770424681948,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 04-09 20:10:22] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 04-09 20:10:22] {1932} INFO - Time taken to find the best model: 354.9090552330017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: log_max_bin\n",
      "[LightGBM] [Warning] Unknown parameter: log_max_bin\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 162435\n",
      "[LightGBM] [Info] Number of data points in the train set: 17307, number of used features: 637\n",
      "[LightGBM] [Info] Start training from score -2.626369\n",
      "[LightGBM] [Info] Start training from score -1.298667\n",
      "[LightGBM] [Info] Start training from score -1.013741\n",
      "[LightGBM] [Info] Start training from score -1.483490\n",
      "[LightGBM] [Info] Start training from score -2.881570\n",
      "[LightGBM] [Info] Start training from score -4.709010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.10523786258143789, log_max_bin=8,\n",
       "               min_child_samples=6, n_estimators=299, num_leaves=4,\n",
       "               reg_alpha=0.06412115021351315, reg_lambda=0.5056770424681948)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code hrlp from that notebook-->[https://www.kaggle.com/code/davidjlochner/base-tfidf-lgbm/notebook]\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(min_df=.05)\n",
    "train_tfid = vectorizer.fit_transform(train['full_text'])\n",
    "test_tfid = vectorizer.transform(test['full_text'])\n",
    "\n",
    "train_y = np.array(train['score'])\n",
    "\n",
    "# Initialize AutoML for hyperparameter optimization\n",
    "aml = AutoML()\n",
    "\n",
    "# Fit AutoML to find the best hyperparameters\n",
    "aml.fit(train_tfid, train_y, estimator_list=['lgbm'], task='classification', metric='macro_f1', time_budget=600)\n",
    "\n",
    "# Retrieve the best hyperparameters found by AutoML\n",
    "best_config = aml.best_config\n",
    "\n",
    "# Initialize LGBMClassifier with the best hyperparameters found\n",
    "model = lgb.LGBMClassifier(**best_config)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_tfid, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7be5e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flatten the nested lists in the 'score' column\n",
    "submission_flat = submission.explode('score')\n",
    "\n",
    "# Write the flattened DataFrame to a CSV file\n",
    "submission_flat.write_csv('submission.csv')\n",
    "\n",
    "# Add insights\n",
    "print(\"Submission generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "891e1699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>score</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>3</td></tr><tr><td>&quot;000d118&quot;</td><td>3</td></tr><tr><td>&quot;000d118&quot;</td><td>4</td></tr><tr><td>&quot;000fe60&quot;</td><td>3</td></tr><tr><td>&quot;000fe60&quot;</td><td>3</td></tr><tr><td>&quot;000fe60&quot;</td><td>4</td></tr><tr><td>&quot;001ab80&quot;</td><td>3</td></tr><tr><td>&quot;001ab80&quot;</td><td>3</td></tr><tr><td>&quot;001ab80&quot;</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌──────────┬───────┐\n",
       "│ essay_id ┆ score │\n",
       "│ ---      ┆ ---   │\n",
       "│ str      ┆ i64   │\n",
       "╞══════════╪═══════╡\n",
       "│ 000d118  ┆ 3     │\n",
       "│ 000d118  ┆ 3     │\n",
       "│ 000d118  ┆ 4     │\n",
       "│ 000fe60  ┆ 3     │\n",
       "│ 000fe60  ┆ 3     │\n",
       "│ 000fe60  ┆ 4     │\n",
       "│ 001ab80  ┆ 3     │\n",
       "│ 001ab80  ┆ 3     │\n",
       "│ 001ab80  ┆ 4     │\n",
       "└──────────┴───────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_actual = pl.read_csv('submission.csv')\n",
    "submission_actual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
